\chapter{Uncovering Analytical Redundancy}

A common tool which Fault Tolerant Control uses in order overcome faults and failures is \textit{redundancy}. System components redundant to each other offer the same functionality with regard to an objective. They may operate simultaneously and cooperatively, or they might only perform a hand-over of the objective in the case where one of them fails. \textit{Hardware redundancy} is about including multiple hardware components to assure that within the pre-specified Mean Time Between Failures (MTBF) the overall system will have at least one component to carry out each necessary objective. Hardware redundancy in fw-UAVs is most prevalent in the form of duplicate sensors or actuators.
However, there is another form of redundancy, \textit{analytical redundancy}. This is about surplus of signal information. If our system structure contains more constraints than variables, ie $ |\mathcal{C}|<|\mathcal{Z}|$, then the system is called \textbf{over-constrained}. In the case of sensor redundancy, there is more than one way (path) to observe (connect) some variables from already known variables, thus removing the need for an extra hardware sensor. In the case of actuator redundancy, uncovering redundancy of an output signal against input signals makes it obvious that there is more than one way to affect the specific output variable, thus alleviating the need for a redundant actuator.
Given the nature of small-scale UAVs, it is very desirable to keep their cost and weight to a minimum. Hence, our goal is to find ways to replace hardware redundancy with analytical redundancy, as much as possible.

\section{Solving the System Graph}

One of the most useful ways one can employ system structural analysis, is indeed to uncover methodically such redundancies within a large-scale system. Instrumental to this goal is the notion of graph matching.

\textbf{Definition: Matching}\\
A matching $\mathcal{M}$ is a subset of $\mathcal{A}$ such that the restrictions of the projections $p_\mathcal{C}$ and $p_\mathcal{Z}$ to $\mathcal{M}$ are injective.\\
\begin{math}
\forall e_1,e_2 \in \mathcal{A} : e_1 \neq e_2 \Rightarrow p_\mathcal{C}(e_1) \neq p_\mathcal{C}(e_2) \wedge p_\mathcal{Z}(e_1) \neq p_\mathcal{Z}(e_2)
\end{math}

This means that given the set of edges $\mathcal{A}$, we select edges so that no two edges have a common vertex. If the cardinality of $\mathcal{M}$ is the maximum possible for a given  $\mathcal{A}$, then the matching is called \textbf{maximal}. If  $\mathcal{M}$ covers all the variables, then it is called \textbf{complete} with respect to  $\mathcal{Z}$

By using the notion of matching, given a system graph, we can reveal analytical redundancy locations, in the form of unmatched constraints. These can be used to "double-check" the correct operation of our system. The difference of the LHS and RDS of an unmatched constraint equation is called a \textbf{residual}. Under nominal system operation all residuals evaluate to zero. If a system constraint is altered, then the unmatched constraint will no longer hold and the associated residual will deviate from zero.

For the previous example of the spring-mass system, a possible complete matching is:
\input{graphMatch}

The matching set is $\mathcal{M}=\left\{(m_1,x),(c_1,\dot{x}),(c_2,v),(c_4,\dot{v})\right\}$. The matched edges are denoted in the graph in bold.

Notice that the matching is complete in respect of the variables and incomplete in respect to the constraints. That leaves room for one residual generator at the node of $c_3$.
The way we can take advantage of the matching is to evaluate the variables adjacent to the unmatched constraint through the given matching and then evaluate the residual.

In our case, the order of operations would be:
\begin{enumerate}
\itemsep-20pt
\item Evaluate $x$ from $x_m$ using $m_1$\\
\item Evaluate $\dot{x}$ from $x$ using $c_1$\\
\item Evaluate $v$ from $x$ using $c_2$\\
\item Evaluate $\dot{v}$ from $x$ using $c_4$\\
\item Evaluate the residual of $c_3$\\
\end{enumerate}

Should everything function as expected the residual should always be zero (or close to the noise floor, for realistic systems). If not, this is an indication that the system has changed and our constraints no longer model it properly.

\section{Residuals and Monitorability}

In the last example, it is easy to understand that a deviation of the residual from zero would undoubtedly be caused by a change of the spring-mass constant $\frac{K}{m}$. The rest of $c_1$ and $c_2$ cannot be "faulty" since they represent the mathematical function of derivation. Any fault detected by the residual is isolated at $c_4$. However, let's suppose that $c_1$ and $c_2$ could represent part of the system model and we would like to be able to isolate the fault either to the system or the differentiators.

A systematic way to check for such possibility can be through, once again, Boolean mappings from the system constraints to the residuals they end up contributing to. If $r$ is a residual generator in our system, which is affected by specific constraints, then we can create a mapping 
$F : r \leftarrow M$

M has as many rows as the residuals of our system and as many columns as the constraints. It is the "signature" of the effect the constraints have onto the residuals. If each column of M is unique, then any constraint violation is isolable through the system residuals, ie 
$c_i \in \mathcal{C}_{isolable} \Leftrightarrow \forall j \neq i: m_i \neq m_j$


For our example, we have\\
$\begin{array}{c|ccclcl}
	\>  & m_1 & c_1 & c_2 & c_3 & c_4 &  \\ \hline
	r_1 &  1  &  1  &  1  & 1   &  1  &
\end{array}$

Clearly no fault is isolable in this configuration; the columns of M are dependent. If we wanted a fault in $c_4$ to be isolable, we would need to modify our system, adding an additional accelerometer sensor to give us the necessary analytical redundancy:\\
\input{graphIsol}

The new Boolean mapping of the constraints onto the residuals is\\
$\begin{array}{c|cccccc}
	\>  & m_1 & m_2 & c_1 & c_2 & c_3 & c_4 \\ \hline
	r_1 &  1  &  1  &  1  &  1  &  1  &  0  \\
	r_2 &  1  &  1  &  0  &  0  &  0  &  1
\end{array}$

For demonstration purposes, if we assume that our sensors ($m_1$ and $m_2$) cannot fail, then the residual mapping will change to the one shown below and the spring-mass time constant fault can be isolated from differentiator faults.\\
$\begin{array}{c|cccc}
	\>  & c_1 & c_2 & c_3 & c_4 \\ \hline
	r_1 &  1  &  1  &  1  &  0  \\
	r_2 &  0  &  0  &  0  &  1
\end{array}$

Using this structured method, we can specify components-constraints whose faults we are interested to isolate, check their isolability properties formally and if there constraint is not isolable then possibly locate injection points where new sensors are needed to achieve isolability.

It would also be interesting to assign weights to each graph edge, in order to model the value of direct quantity measurements against quantities derived through extensive manipulation of the already known variables.